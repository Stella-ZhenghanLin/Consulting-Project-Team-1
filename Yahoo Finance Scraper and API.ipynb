{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the base input dataset\n",
    "df = pd.read_excel('D:\\SDG2000-shareable-list_28.04.2022_initial_data.xlsx', sheet_name = '2. SDG2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEDOL Code'] = df['SEDOL Code'].fillna(0) # filling any missing SEDOL code companies with 0s\n",
    "df = df.loc[df['SEDOL Code'] != 0] # filtering out the missing SEDOL code companies\n",
    "df = df.reset_index(drop = True) # Reseting the index of the dataframe\n",
    "df['Ticker'] = '' # Adding a new blank column where the scraped tickers can be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, Sedol) in enumerate(df['SEDOL Code'][0:1444]): \n",
    "    \n",
    "    company_sedol = Sedol # Creating a new variable for a specific company name\n",
    "    options = Options() # Creating advanced options for the Chrome webdriver\n",
    "    ua = UserAgent() # Creating useragents as part of the protocol to prevent scraper being detected\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}') # Adding in the randomly generated useragent\n",
    "    options.add_experimental_option('useAutomationExtension', False) # Additional tools to prevent detection\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "    driver = webdriver.Chrome('C:\\chromedriver.exe',options=options) # Launching a webdriver with the options\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\") \n",
    "    \n",
    "    driver.get('https://finance.yahoo.com/') # Yahoo Finance website\n",
    "\n",
    "    wait = WebDriverWait(driver,5) # Defining wait variable for later use\n",
    "    action = ActionChains(driver) # Defining action variable for later use\n",
    "    \n",
    "    # Cookies, this chunk first goes into more options, clicks reject all, and then clicks confirm\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div/div/div/form/div[2]/div[2]/a')))\n",
    "    elem = driver.find_element(By.XPATH, '/html/body/div/div/div/div/form/div[2]/div[2]/a')\n",
    "    elem.click()\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div/form/div[2]/div[3]/div[2]/div/div/div[2]/div[2]/div[2]/label/span[2]')))\n",
    "    elem = driver.find_element(By.XPATH, '/html/body/div/div/form/div[2]/div[3]/div[2]/div/div/div[2]/div[2]/div[2]/label/span[2]')\n",
    "    elem.click()\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div/form/div[3]/div/div/button')))\n",
    "    elem = driver.find_element(By.XPATH, '/html/body/div/div/form/div[3]/div/div/button')\n",
    "    elem.click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.XPATH,'/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/input[1]' )))\n",
    "    elem = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/input[1]') # Finding the search bar\n",
    "    try:\n",
    "        elem.clear() # Clearing any default values typed into the search bar\n",
    "        elem.send_keys(company_sedol) # Typing in the company SEDOL code in the search bar \n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/div[1]/button')))\n",
    "        elem = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/div[1]/button')\n",
    "        elem.click()\n",
    "        \n",
    "        searchTextbox = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/div/div[2]/div[1]/div[1]/h1'))) # Waiting\n",
    "        # until the suggested company page shows up after searching with the SEDOL code.\n",
    "\n",
    "    \n",
    "        # Find the name of company ticker on the page and add it to the ticker column\n",
    "        company_ticker_yahoo_scraper = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/div/div[2]/div[1]/div[1]/h1')\n",
    "        company_ticker_yahoo = company_ticker_yahoo_scraper.text\n",
    "        df.iat[index,14] = (company_ticker_yahoo.split(\"(\")[-1]).split(\")\")[0]\n",
    "        \n",
    "        driver.close() # Closing the driver\n",
    "    # If the company is not found by SEDOL code, then the ISIN is used to try and get the company ticker    \n",
    "    except TimeoutException:\n",
    "        try:\n",
    "            company_ISIN = df['ISIN'][index]\n",
    "            driver.get('https://finance.yahoo.com/')\n",
    "            wait.until(EC.presence_of_element_located((By.XPATH,'/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/input[1]' )))\n",
    "            elem = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/input[1]')\n",
    "            elem.send_keys(company_sedol) # Typing in the company SEDOL code in the search bar \n",
    "            wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/div[1]/button')))\n",
    "            elem = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/div[1]/button')\n",
    "            elem.click()\n",
    "        \n",
    "            searchTextbox = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/div/div[2]/div[1]/div[1]/h1'))) # Waiting\n",
    "            # until the suggested company page shows up after searching with the SEDOL code.\n",
    "\n",
    "    \n",
    "            # Find the name of company ticker on the page and add it to the ticker column\n",
    "            company_ticker_yahoo_scraper = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[6]/div/div/div/div[2]/div[1]/div[1]/h1')\n",
    "            company_ticker_yahoo = company_ticker_yahoo_scraper.text\n",
    "            df.iat[index,14] = (company_ticker_yahoo.split(\"(\")[-1]).split(\")\")[0]\n",
    "        \n",
    "            driver.close() # Closing the driver \n",
    "        except TimeoutException as ex: # If the company name is not found and a timeout error is raised,\n",
    "            # add NotFound to the Ticker column for the current company\n",
    "            isrunning = 0\n",
    "            df.iloc[index,14] = 'NotFound'\n",
    "            driver.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('SDG2000_Yahoo_Tickers.xlsx') # exporting the scraped database as an excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = (df['Ticker'].tolist())[0:1000]\n",
    "\n",
    "# Retrieve Yahoo! Finance Sustainability metrics for each ticker\n",
    "esg = pd.DataFrame()\n",
    "for i in tickers:\n",
    "    print(i)\n",
    "    i_y = yf.Ticker(i)\n",
    "    try:\n",
    "        if i_y.sustainability is not None:\n",
    "            temp = pd.DataFrame.transpose(i_y.sustainability)\n",
    "            temp['company_ticker'] = str(i_y.ticker)\n",
    "            # print(temp)\n",
    "            esg = esg.append(temp)\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg.to_excel('SDG2000_Yahoo_Sustainability.xlsx') # exporting the scraped database as an excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = (df['Ticker'].tolist())[0:1000]\n",
    "\n",
    "# Retrieve Yahoo! Finance financial metrics for each ticker\n",
    "company_metrics = {}\n",
    "for company in tickers:\n",
    "    company_metrics[company] = {}\n",
    "    company_info = yf.Ticker(company)\n",
    "    try:\n",
    "        if company_info.info is not None:\n",
    "            company_metrics[company]['Profit_Margins'] = company_info.info['profitMargins']\n",
    "            company_metrics[company]['Market_Cap'] = company_info.info['marketCap']\n",
    "            company_metrics[company]['Total_Revenue'] = company_info.info['totalRevenue']\n",
    "            company_metrics[company]['Enterprise_to_Revenue'] = company_info.info['enterpriseToRevenue']\n",
    "            company_metrics[company]['Price_To_Sales_Trailing12Months'] = company_info.info['priceToSalesTrailing12Months']\n",
    "            company_metrics[company]['Beta'] = company_info.info['beta']\n",
    "    except:\n",
    "        pass\n",
    "finance = pd.DataFrame.from_dict(company_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance.to_excel('SDG2000_Yahoo_Financial.xlsx') # exporting the scraped database as an excel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
